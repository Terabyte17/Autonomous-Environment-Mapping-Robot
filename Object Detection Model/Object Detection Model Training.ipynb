{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Object Detection Robotics.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNcnW5EtULoDvpgBdL21BJ/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5tLHABcd1hap","colab_type":"code","outputId":"5e2f8863-742f-4993-c841-5072d13a1cfc","executionInfo":{"status":"ok","timestamp":1591973834827,"user_tz":-330,"elapsed":97654,"user":{"displayName":"Yash Sahijwani 4-Year B.Tech. Electronics Engineering","photoUrl":"","userId":"02680149716594177845"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6iqo-uaMIMb0","colab_type":"code","outputId":"3d5a1705-d435-445e-9749-773d70ed0965","executionInfo":{"status":"ok","timestamp":1591973843155,"user_tz":-330,"elapsed":105974,"user":{"displayName":"Yash Sahijwani 4-Year B.Tech. Electronics Engineering","photoUrl":"","userId":"02680149716594177845"}},"colab":{"base_uri":"https://localhost:8080/","height":269}},"source":["!pip install imageai"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting imageai\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/99/4023e191a343fb23f01ae02ac57a5ca58037c310e8d8c62f87638a3bafc7/imageai-2.1.5-py3-none-any.whl (180kB)\n","\r\u001b[K     |█▉                              | 10kB 16.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 20kB 212kB/s eta 0:00:01\r\u001b[K     |█████▍                          | 30kB 289kB/s eta 0:00:01\r\u001b[K     |███████▎                        | 40kB 330kB/s eta 0:00:01\r\u001b[K     |█████████                       | 51kB 254kB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 61kB 288kB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 71kB 323kB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 81kB 352kB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 92kB 378kB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 102kB 353kB/s eta 0:00:01\r\u001b[K     |████████████████████            | 112kB 353kB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 122kB 353kB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 133kB 353kB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 143kB 353kB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 153kB 353kB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 163kB 353kB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 174kB 353kB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 353kB/s \n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from imageai) (2.10.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageai) (7.0.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imageai) (3.2.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageai) (1.18.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imageai) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->imageai) (1.12.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (1.2.0)\n","Installing collected packages: imageai\n","Successfully installed imageai-2.1.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7xBLs3WrIPHQ","colab_type":"code","outputId":"10e8235e-6981-4efe-e089-3cf768f96152","executionInfo":{"status":"ok","timestamp":1591973912561,"user_tz":-330,"elapsed":175374,"user":{"displayName":"Yash Sahijwani 4-Year B.Tech. Electronics Engineering","photoUrl":"","userId":"02680149716594177845"}},"colab":{"base_uri":"https://localhost:8080/","height":675}},"source":["!pip install tensorflow-gpu==1.13.1"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-gpu==1.13.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n","\u001b[K     |████████████████████████████████| 345.2MB 52kB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.34.2)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.9.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.2)\n","Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n","\u001b[K     |████████████████████████████████| 368kB 17.5MB/s \n","\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.0.8)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.12.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (3.10.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.29.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.18.5)\n","Collecting tensorboard<1.14.0,>=1.13.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 33.2MB/s \n","\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.3.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n","Collecting mock>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (2.10.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1) (47.1.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.2.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.0.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.1.0)\n","\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 1.13.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorflow-estimator<2.3.0,>=2.2.0, but you'll have tensorflow-estimator 1.13.0 which is incompatible.\u001b[0m\n","Installing collected packages: mock, tensorflow-estimator, tensorboard, tensorflow-gpu\n","  Found existing installation: tensorflow-estimator 2.2.0\n","    Uninstalling tensorflow-estimator-2.2.0:\n","      Successfully uninstalled tensorflow-estimator-2.2.0\n","  Found existing installation: tensorboard 2.2.2\n","    Uninstalling tensorboard-2.2.2:\n","      Successfully uninstalled tensorboard-2.2.2\n","Successfully installed mock-4.0.2 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YPq2iPeJ2nB_","colab_type":"code","outputId":"e39200dd-839f-4c40-e125-1256cbc3b02b","executionInfo":{"status":"ok","timestamp":1591973915051,"user_tz":-330,"elapsed":177858,"user":{"displayName":"Yash Sahijwani 4-Year B.Tech. Electronics Engineering","photoUrl":"","userId":"02680149716594177845"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["import os\n","import numpy as np\n","from imageai.Detection.Custom import DetectionModelTrainer,CustomObjectDetection"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"0mGj_ySI3DOF","colab_type":"code","outputId":"bd6cf22b-6a9c-4cb9-d7cc-6448e1ce8202","executionInfo":{"status":"error","timestamp":1591973917367,"user_tz":-330,"elapsed":180168,"user":{"displayName":"Yash Sahijwani 4-Year B.Tech. Electronics Engineering","photoUrl":"","userId":"02680149716594177845"}},"colab":{"base_uri":"https://localhost:8080/","height":354}},"source":["trainer=DetectionModelTrainer()\n","trainer.setModelTypeAsYOLOv3()\n","trainer.setDataDirectory(data_directory=\"/content/drive/My Drive/husky\")\n","trainer.setTrainConfig(object_names_array=[\"husky\"],batch_size=4,num_experiments=5,train_from_pretrained_model='/content/drive/My Drive/yolo.h5')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Generating anchor boxes for training images and annotation...\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-de4fdc515510>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetModelTypeAsYOLOv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetDataDirectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/My Drive/husky\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetTrainConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_names_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"husky\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_experiments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_from_pretrained_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/My Drive/yolo.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageai/Detection/Custom/__init__.py\u001b[0m in \u001b[0;36msetTrainConfig\u001b[0;34m(self, object_names_array, batch_size, num_experiments, train_from_pretrained_model)\u001b[0m\n\u001b[1;32m    169\u001b[0m         self.__model_anchors, self.__inference_anchors = generateAnchors(self.__train_annotations_folder,\n\u001b[1;32m    170\u001b[0m                                                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__train_images_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                                                                           self.__train_cache_file, self.__model_labels)\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__model_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_names_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageai/Detection/Custom/gen_anchors.py\u001b[0m in \u001b[0;36mgenerateAnchors\u001b[0;34m(train_annotation_folder, train_image_folder, train_cache_file, model_labels)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mannotation_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_kmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_anchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# write anchors to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageai/Detection/Custom/gen_anchors.py\u001b[0m in \u001b[0;36mrun_kmeans\u001b[0;34m(ann_dims, anchor_num)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mIOU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# distances.shape = (ann_num, anchor_num)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageai/Detection/Custom/gen_anchors.py\u001b[0m in \u001b[0;36mIOU\u001b[0;34m(ann, centroids)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcentroid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mc_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcentroid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mc_w\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mc_h\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"Jk3tz0f132jR","colab_type":"code","outputId":"1e1ca1cd-2fb8-4b38-8e39-92a2103dff8b","executionInfo":{"status":"ok","timestamp":1591911813963,"user_tz":-330,"elapsed":1775047,"user":{"displayName":"Yash Sahijwani 4-Year B.Tech. Electronics Engineering","photoUrl":"","userId":"02680149716594177845"}},"colab":{"base_uri":"https://localhost:8080/","height":457}},"source":["trainer.trainModel()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training on: \t['husky']\n","Training with Batch Size:  4\n","Number of Experiments:  5\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/imageai/Detection/Custom/yolo.py:24: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Training with transfer learning from pretrained Model\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n","  warnings.warn('`epsilon` argument is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/5\n","2008/2008 [==============================] - 2045s 1s/step - loss: 18.6443 - yolo_layer_1_loss: 2.5687 - yolo_layer_2_loss: 5.4291 - yolo_layer_3_loss: 10.6466 - val_loss: 13.9804 - val_yolo_layer_1_loss: 3.1880 - val_yolo_layer_2_loss: 3.3045 - val_yolo_layer_3_loss: 4.3653\n","Epoch 2/5\n","2008/2008 [==============================] - 1947s 970ms/step - loss: 6.7472 - yolo_layer_1_loss: 1.6263 - yolo_layer_2_loss: 2.1341 - yolo_layer_3_loss: 2.9868 - val_loss: 8.6868 - val_yolo_layer_1_loss: 3.7580 - val_yolo_layer_2_loss: 2.5448 - val_yolo_layer_3_loss: 3.6831\n","Epoch 3/5\n","2008/2008 [==============================] - 1985s 989ms/step - loss: 6.2630 - yolo_layer_1_loss: 1.9767 - yolo_layer_2_loss: 1.8826 - yolo_layer_3_loss: 2.4037 - val_loss: 8.5098 - val_yolo_layer_1_loss: 2.7372 - val_yolo_layer_2_loss: 1.8445 - val_yolo_layer_3_loss: 2.7462\n","Epoch 4/5\n","2008/2008 [==============================] - 1973s 983ms/step - loss: 5.6660 - yolo_layer_1_loss: 1.8366 - yolo_layer_2_loss: 1.6716 - yolo_layer_3_loss: 2.1579 - val_loss: 6.1527 - val_yolo_layer_1_loss: 2.5932 - val_yolo_layer_2_loss: 1.9353 - val_yolo_layer_3_loss: 2.0951\n","Epoch 5/5\n","2008/2008 [==============================] - 1962s 977ms/step - loss: 4.6567 - yolo_layer_1_loss: 1.1664 - yolo_layer_2_loss: 1.5216 - yolo_layer_3_loss: 1.9687 - val_loss: 2.4012 - val_yolo_layer_1_loss: 0.9622 - val_yolo_layer_2_loss: 1.5680 - val_yolo_layer_3_loss: 1.7914\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1X-6HiAJHDL6","colab_type":"code","outputId":"db3c4582-4e3b-4cf0-bdff-fe0e29a106c5","executionInfo":{"status":"ok","timestamp":1591912487619,"user_tz":-330,"elapsed":442226,"user":{"displayName":"Yash Sahijwani 4-Year B.Tech. Electronics Engineering","photoUrl":"","userId":"02680149716594177845"}},"colab":{"base_uri":"https://localhost:8080/","height":739}},"source":["trainer=DetectionModelTrainer()\n","trainer.setModelTypeAsYOLOv3()\n","trainer.setDataDirectory(data_directory='/content/drive/My Drive/husky')\n","metrics=trainer.evaluateModel(model_path='/content/drive/My Drive/husky/models',json_path='/content/drive/My Drive/husky/json/detection_config.json',iou_threshold=0.5,object_threshold=0.3,nms_threshold=0.5)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Starting Model evaluation....\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n","  warnings.warn('No training configuration found in save file: '\n"],"name":"stderr"},{"output_type":"stream","text":["Model File:  /content/drive/My Drive/husky/models/detection_model-ex-001--loss-0018.644.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","husky: 0.6653\n","mAP: 0.6653\n","===============================\n","Model File:  /content/drive/My Drive/husky/models/detection_model-ex-002--loss-0006.747.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","husky: 0.8360\n","mAP: 0.8360\n","===============================\n","Model File:  /content/drive/My Drive/husky/models/detection_model-ex-003--loss-0006.263.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","husky: 0.7106\n","mAP: 0.7106\n","===============================\n","Model File:  /content/drive/My Drive/husky/models/detection_model-ex-004--loss-0005.666.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","husky: 0.8545\n","mAP: 0.8545\n","===============================\n","Model File:  /content/drive/My Drive/husky/models/detection_model-ex-005--loss-0004.657.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","husky: 0.9668\n","mAP: 0.9668\n","===============================\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u4aRWA4HKT7Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f96bf12e-0c1d-4ed5-e76d-333d93de3011","executionInfo":{"status":"ok","timestamp":1591974230374,"user_tz":-330,"elapsed":18893,"user":{"displayName":"Yash Sahijwani 4-Year B.Tech. Electronics Engineering","photoUrl":"","userId":"02680149716594177845"}}},"source":["detector=CustomObjectDetection()\n","detector.setModelTypeAsYOLOv3()\n","detector.setModelPath('/content/drive/My Drive/husky/models/detection_model-ex-005--loss-0004.657.h5')\n","detector.setJsonPath('/content/drive/My Drive/husky/json/detection_config.json')\n","detector.loadModel()\n","detections=detector.detectObjectsFromImage(input_image='/content/drive/My Drive/husky/train/images/husky_0_3.png',output_image_path='/content/drive/My Drive/Husky_detected.png')\n","for detection in detections:\n","  if detection[\"name\"]=='husky':\n","    if detection[\"percentage_probability\"]>30:\n","      print(\"Husky detected!\")"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Husky detected!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"auJt4yDd0qUx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}